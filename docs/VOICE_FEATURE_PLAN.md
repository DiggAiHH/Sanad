# ğŸ™ï¸ Voice Feature Plan - Sanad

> **Status:** âœ… IMPLEMENTIERT - Core Services + 16 Sprachen  
> **Erstellt:** 2026-01-12  
> **Letzte Aktualisierung:** 2026-01-12

---

## 0. Implementierungs-Status

| Komponente | Status | Details |
|------------|--------|---------|
| TTS Service | âœ… Done | `tts_service.dart` - VollstÃ¤ndig |
| STT Service | âœ… Done | `stt_service.dart` - VollstÃ¤ndig |
| Command Parser | âœ… Done | Fuzzy Matching mit Levenshtein |
| Announcement Builder | âœ… Done | SSML Support |
| Voice Strings DE | âœ… Done | Phase 0 |
| Voice Strings EN | âœ… Done | Phase 0 |
| Voice Strings TR | âœ… Done | Phase 0 |
| Voice Strings AR | âœ… Done | Phase 0 (RTL) |
| Voice Strings RU | âœ… Done | Phase 1 (Slavic Plurals) |
| Voice Strings PL | âœ… Done | Phase 1 (Slavic Plurals) |
| Voice Strings FR | âœ… Done | Phase 1 |
| Voice Strings ES | âœ… Done | Phase 1 |
| Voice Strings IT | âœ… Done | Phase 2 |
| Voice Strings PT | âœ… Done | Phase 2 |
| Voice Strings UK | âœ… Done | Phase 2 (Slavic Plurals) |
| Voice Strings FA | âœ… Done | Phase 3 (RTL) |
| Voice Strings UR | âœ… Done | Phase 3 (RTL) |
| Voice Strings VI | âœ… Done | Phase 3 |
| Voice Strings RO | âœ… Done | Phase 3 |
| Voice Strings EL | âœ… Done | Phase 3 |
| Voice Provider | âœ… Done | Riverpod Integration |
| Voice Widgets | âœ… Done | VoiceButton, SpeakButton, WaveformIndicator |
| Unit Tests | âœ… Done | 4 Test-Dateien |
| App Integration | â³ Pending | Patient/Staff/Admin App Integration |

---

## 1. Ãœbersicht

Voice-Funktionen fÃ¼r alle Sanad-Apps mit Multi-Language Support.

### Ziel-Apps:
| App | PrimÃ¤re Voice-Features |
|-----|------------------------|
| **Patient App** | Ticket-Status hÃ¶ren, Sprachbefehle, Barrierefreiheit |
| **Staff App** | Patienten aufrufen, Ansagen, Diktierfunktion |
| **Admin App** | Statistik-Vorlesen, Sprachsteuerung |

---

## 2. UnterstÃ¼tzte Sprachen

### Phase 1 (MVP):
| Sprache | Code | TTS | STT | Priority |
|---------|------|-----|-----|----------|
| ğŸ‡©ğŸ‡ª Deutsch | `de-DE` | âœ… | âœ… | P0 |
| ğŸ‡¬ğŸ‡§ Englisch | `en-GB` | âœ… | âœ… | P0 |
| ğŸ‡¹ğŸ‡· TÃ¼rkisch | `tr-TR` | âœ… | âœ… | P0 |
| ğŸ‡¸ğŸ‡¦ Arabisch | `ar-SA` | âœ… | âœ… | P0 |

### Phase 2 (Erweiterung):
| Sprache | Code | TTS | STT | Priority |
|---------|------|-----|-----|----------|
| ğŸ‡·ğŸ‡º Russisch | `ru-RU` | âœ… | âœ… | P1 |
| ğŸ‡µğŸ‡± Polnisch | `pl-PL` | âœ… | âœ… | P1 |
| ğŸ‡«ğŸ‡· FranzÃ¶sisch | `fr-FR` | âœ… | âœ… | P1 |
| ğŸ‡ªğŸ‡¸ Spanisch | `es-ES` | âœ… | âœ… | P1 |
| ğŸ‡®ğŸ‡¹ Italienisch | `it-IT` | âœ… | âœ… | P2 |
| ğŸ‡µğŸ‡¹ Portugiesisch | `pt-PT` | âœ… | âœ… | P2 |
| ğŸ‡ºğŸ‡¦ Ukrainisch | `uk-UA` | âœ… | âœ… | P2 |
| ğŸ‡®ğŸ‡· Farsi/Persisch | `fa-IR` | âœ… | âœ… | P2 |
| ğŸ‡µğŸ‡° Urdu | `ur-PK` | âœ… | âœ… | P2 |
| ğŸ‡»ğŸ‡³ Vietnamesisch | `vi-VN` | âœ… | âœ… | P3 |
| ğŸ‡·ğŸ‡´ RumÃ¤nisch | `ro-RO` | âœ… | âœ… | P3 |
| ğŸ‡¬ğŸ‡· Griechisch | `el-GR` | âœ… | âœ… | P3 |

---

## 3. Technologie-Stack

### 3.1 Text-to-Speech (TTS)
```
Option A: flutter_tts (Offline, Device-native)
  - Pro: Keine API-Kosten, funktioniert offline
  - Con: StimmenqualitÃ¤t variiert je nach GerÃ¤t

Option B: Google Cloud TTS API
  - Pro: Hochwertige Neural Voices
  - Con: Kosten pro Request, braucht Internet

Option C: Azure Cognitive Services Speech
  - Pro: Exzellente QualitÃ¤t, SSML Support
  - Con: Kosten, Azure-AbhÃ¤ngigkeit

EMPFEHLUNG: Hybrid-Ansatz
  - Primary: flutter_tts (offline)
  - Fallback: Cloud TTS fÃ¼r bessere QualitÃ¤t wenn online
```

### 3.2 Speech-to-Text (STT)
```
Option A: speech_to_text (Flutter Plugin)
  - Pro: Native Device Recognition
  - Con: QualitÃ¤t variiert

Option B: Google Cloud Speech-to-Text
  - Pro: Hohe Genauigkeit, viele Sprachen
  - Con: Kosten, Latenz

Option C: Whisper (OpenAI) via API
  - Pro: Beste Genauigkeit
  - Con: Kosten, nur API

EMPFEHLUNG: 
  - Primary: speech_to_text fÃ¼r kurze Befehle
  - Premium: Whisper API fÃ¼r Diktierfunktion
```

### 3.3 Packages (Flutter)
```yaml
dependencies:
  flutter_tts: ^3.8.5
  speech_to_text: ^6.6.0
  permission_handler: ^11.3.0
  audio_session: ^0.1.18
  
  # Optional fÃ¼r Cloud-Integration
  googleapis: ^12.0.0
  azure_speech_sdk: ^1.0.0  # Wenn verfÃ¼gbar
```

---

## 4. Feature-Spezifikation

### 4.1 Patient App Voice Features

#### A) Ticket-Status Vorlesen (TTS)
```
Trigger: 
  - Automatisch bei StatusÃ¤nderung
  - Button "Status vorlesen"
  - Accessibility: Screen Reader Support

Ansagen (Beispiele):
  DE: "Ihre Ticketnummer A-047. Sie sind an Position 3. 
       GeschÃ¤tzte Wartezeit: 12 Minuten."
  EN: "Your ticket number A-047. You are at position 3. 
       Estimated wait time: 12 minutes."
  TR: "Bilet numaranÄ±z A-047. SÄ±rada 3. sÄ±radasÄ±nÄ±z. 
       Tahmini bekleme sÃ¼resi: 12 dakika."
  AR: "Ø±Ù‚Ù… ØªØ°ÙƒØ±ØªÙƒ A-047. Ø£Ù†Øª ÙÙŠ Ø§Ù„Ù…Ø±ÙƒØ² 3. 
       ÙˆÙ‚Øª Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø± Ø§Ù„Ù…ØªÙˆÙ‚Ø¹: 12 Ø¯Ù‚ÙŠÙ‚Ø©."
```

#### B) Aufruf-Benachrichtigung (TTS)
```
Trigger: Ticket wird aufgerufen (Push + In-App)

Ansagen:
  DE: "Achtung! Ihre Nummer A-047 wurde aufgerufen! 
       Bitte begeben Sie sich zu Zimmer 3."
  EN: "Attention! Your number A-047 has been called! 
       Please proceed to Room 3."
  ...
  
Audio: 
  - Attention Sound vor Ansage
  - Vibration Pattern: Long-Short-Long
  - Repeat: 2x mit 3s Pause
```

#### C) Sprachbefehle (STT)
```
Befehle:
  "Status" / "Mein Status" â†’ Ticket-Status vorlesen
  "Wartezeit" â†’ Nur Wartezeit ansagen
  "Position" â†’ Nur Position ansagen
  "Abbrechen" / "Stop" â†’ Ticket stornieren (mit BestÃ¤tigung)
  "Hilfe" â†’ VerfÃ¼gbare Befehle auflisten

Aktivierung:
  - Hold-to-Talk Button
  - Wake Word: "Hey Sanad" (Optional, Phase 2)
```

#### D) Accessibility / Barrierefreiheit
```
- VoiceOver (iOS) / TalkBack (Android) Support
- Semantic Labels fÃ¼r alle UI-Elemente
- High Contrast Mode mit Voice Feedback
- GroÃŸe Touch-Targets fÃ¼r Voice-Buttons
```

---

### 4.2 Staff App Voice Features

#### A) Patienten-Aufruf (TTS)
```
Trigger: Staff drÃ¼ckt "Aufrufen" Button

Ausgabe:
  - Ãœber Lautsprecher im Wartezimmer (Bluetooth/WiFi Speaker)
  - Push an Patient App

Ansage:
  DE: "Nummer A-047, bitte zu Zimmer 3."
  EN: "Number A-047, please proceed to Room 3."
  
SSML-Beispiel:
  <speak>
    <prosody rate="slow" pitch="+10%">
      Nummer <say-as interpret-as="characters">A</say-as>
      <break time="100ms"/>
      <say-as interpret-as="digits">047</say-as>
    </prosody>
    <break time="500ms"/>
    Bitte zu Zimmer 3.
  </speak>
```

#### B) Diktierfunktion fÃ¼r Notizen (STT)
```
Use Case: Arzt/MFA diktiert Patientennotizen

Features:
  - Continuous Recording
  - Medizinische Fachbegriffe (Custom Vocabulary)
  - Interpunktion: "Punkt", "Komma", "Neue Zeile"
  - "LÃ¶schen" zum RÃ¼ckgÃ¤ngigmachen

Sprach-Erkennung:
  - Medizinisches Vokabular pro Sprache
  - ICD-10 Codes
  - Medikamentennamen
```

#### C) Sprachsteuerung Staff-UI (STT)
```
Befehle:
  "NÃ¤chster Patient" â†’ NÃ¤chstes Ticket aufrufen
  "Patient fertig" â†’ Aktuelles Ticket abschlieÃŸen
  "Pause" â†’ Queue pausieren
  "Ãœbersicht" â†’ Dashboard-Stats vorlesen
  
Hands-Free Modus:
  - FÃ¼r BehandlungsrÃ¤ume
  - Wake Word aktiviert
  - BestÃ¤tigungs-Sounds
```

---

### 4.3 Admin App Voice Features

#### A) Dashboard-Statistiken vorlesen (TTS)
```
Trigger: "Statistik vorlesen" Button oder Sprachbefehl

Ansage:
  DE: "Aktuelle Ãœbersicht: 
       23 Patienten warten. 
       Durchschnittliche Wartezeit: 18 Minuten.
       5 Mitarbeiter aktiv.
       Queue A hat 12 wartende Patienten."
```

#### B) Sprachbefehle Admin (STT)
```
Befehle:
  "Zeige Queue A" â†’ Navigation zu Queue A
  "Ã–ffne Einstellungen" â†’ Settings Ã¶ffnen
  "Mitarbeiter Ãœbersicht" â†’ Staff-Liste
  "Export heute" â†’ Tagesreport generieren
```

---

## 5. Architektur

### 5.1 Package-Struktur
```
packages/
â”œâ”€â”€ voice/                          # Neues Voice Package
â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”‚   â”œâ”€â”€ tts/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ tts_service.dart
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ tts_config.dart
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ voice_profiles.dart
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ stt/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ stt_service.dart
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ stt_config.dart
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ command_parser.dart
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ medical_vocabulary.dart
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ announcements/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ announcement_builder.dart
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ announcement_templates.dart
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ssml_builder.dart
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ localization/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ voice_strings_de.dart
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ voice_strings_en.dart
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ voice_strings_tr.dart
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ voice_strings_ar.dart
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ voice_strings.dart
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â””â”€â”€ widgets/
â”‚   â”‚   â”‚       â”œâ”€â”€ voice_button.dart
â”‚   â”‚   â”‚       â”œâ”€â”€ speak_button.dart
â”‚   â”‚   â”‚       â”œâ”€â”€ listen_indicator.dart
â”‚   â”‚   â”‚       â””â”€â”€ voice_settings_tile.dart
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ voice.dart              # Barrel export
â”‚   â”‚
â”‚   â”œâ”€â”€ test/
â”‚   â”‚   â”œâ”€â”€ tts_service_test.dart
â”‚   â”‚   â”œâ”€â”€ stt_service_test.dart
â”‚   â”‚   â””â”€â”€ command_parser_test.dart
â”‚   â”‚
â”‚   â””â”€â”€ pubspec.yaml
```

### 5.2 Service-Interfaces
```
abstract class TtsService {
  Future<void> speak(String text, {String? languageCode});
  Future<void> speakAnnouncement(Announcement announcement);
  Future<void> stop();
  Future<void> setLanguage(String languageCode);
  Future<void> setVoice(VoiceProfile profile);
  Future<List<VoiceProfile>> getAvailableVoices();
  Stream<TtsState> get stateStream;
}

abstract class SttService {
  Future<void> startListening({String? languageCode});
  Future<void> stopListening();
  Stream<SttResult> get resultStream;
  Stream<SttState> get stateStream;
  Future<bool> hasPermission();
  Future<void> requestPermission();
}

abstract class VoiceCommandService {
  void registerCommand(VoiceCommand command);
  void unregisterCommand(String commandId);
  Stream<VoiceCommandMatch> get commandStream;
}
```

### 5.3 State Management
```
VoiceState {
  ttsState: TtsState (idle, speaking, loading)
  sttState: SttState (idle, listening, processing)
  currentLanguage: String
  selectedVoice: VoiceProfile?
  isEnabled: bool
  volume: double
  speechRate: double
}

VoiceCubit / VoiceNotifier:
  - speak(text)
  - speakTicketStatus(ticket)
  - speakAnnouncement(ticketNumber, room)
  - startListening()
  - stopListening()
  - setLanguage(code)
  - toggleVoice()
```

---

## 6. Lokalisierungs-Strings

### 6.1 Template-Struktur
```dart
// voice_strings.dart
abstract class VoiceStrings {
  String get ticketStatusTemplate;
  String get ticketCalledTemplate;
  String get waitTimeTemplate;
  String get positionTemplate;
  
  // Interpolation
  String ticketStatus({
    required String ticketNumber,
    required int position,
    required int waitMinutes,
  });
  
  String ticketCalled({
    required String ticketNumber,
    required String room,
  });
}
```

### 6.2 Beispiel-Implementierung (DE)
```dart
class VoiceStringsDe implements VoiceStrings {
  @override
  String ticketStatus({...}) =>
    'Ihre Ticketnummer $ticketNumber. '
    'Sie sind an Position $position. '
    'GeschÃ¤tzte Wartezeit: $waitMinutes Minuten.';
    
  @override
  String ticketCalled({...}) =>
    'Achtung! Ihre Nummer $ticketNumber wurde aufgerufen! '
    'Bitte begeben Sie sich zu $room.';
}
```

---

## 7. Berechtigungen

### Android (AndroidManifest.xml)
```xml
<uses-permission android:name="android.permission.RECORD_AUDIO" />
<uses-permission android:name="android.permission.INTERNET" />
<uses-permission android:name="android.permission.BLUETOOTH" />
<uses-permission android:name="android.permission.BLUETOOTH_CONNECT" />

<queries>
  <intent>
    <action android:name="android.speech.RecognitionService" />
  </intent>
  <intent>
    <action android:name="android.intent.action.TTS_SERVICE" />
  </intent>
</queries>
```

### iOS (Info.plist)
```xml
<key>NSMicrophoneUsageDescription</key>
<string>FÃ¼r Sprachbefehle und Diktierfunktion</string>
<key>NSSpeechRecognitionUsageDescription</key>
<string>FÃ¼r Spracherkennung und Befehle</string>
```

---

## 8. UI-Komponenten

### 8.1 VoiceButton (Hold-to-Talk)
```
Design:
  - Runder Button mit Mikrofon-Icon
  - Animation: Pulsierend wÃ¤hrend Aufnahme
  - Farbwechsel: Grau â†’ Primary (aktiv) â†’ Rot (Error)
  - Waveform-Visualisierung
  
States:
  - idle: Mikrofon-Icon, "Halten zum Sprechen"
  - listening: Pulsierend, Waveform
  - processing: Spinner
  - error: Rot, Retry-Option
```

### 8.2 SpeakButton (Text vorlesen)
```
Design:
  - Lautsprecher-Icon
  - Toggle: Sprechen/Stop
  
States:
  - idle: Speaker Icon
  - speaking: Animierte Schallwellen, Stop-Icon
```

### 8.3 VoiceSettingsTile
```
Settings UI:
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ ğŸ™ï¸ Sprachfunktionen                â”‚
  â”‚    â—‹ Aktiviert                      â”‚
  â”‚                                     â”‚
  â”‚ Sprache: [Deutsch â–¼]                â”‚
  â”‚ Stimme:  [Weiblich â–¼]               â”‚
  â”‚                                     â”‚
  â”‚ Geschwindigkeit: â”â”â”â”â—â”â”â” 1.0x      â”‚
  â”‚ LautstÃ¤rke:      â”â”â”â”â”â”â—â” 80%       â”‚
  â”‚                                     â”‚
  â”‚ [Test-Ansage abspielen]             â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 9. Backend-Integration

### 9.1 WebSocket Events (Echtzeit-Aufruf)
```json
{
  "event": "ticket_called",
  "data": {
    "ticket_number": "A-047",
    "room": "Zimmer 3",
    "patient_language": "de-DE",
    "announcement_audio_url": "https://..." // Optional: Pre-rendered
  }
}
```

### 9.2 Ansagen-API (Optional)
```
POST /api/v1/announcements/generate
{
  "template": "ticket_called",
  "language": "de-DE",
  "variables": {
    "ticket_number": "A-047",
    "room": "Zimmer 3"
  },
  "voice": "female_neural"
}

Response:
{
  "audio_url": "https://storage.../announcement_xyz.mp3",
  "text": "Nummer A-047, bitte zu Zimmer 3.",
  "duration_ms": 3200
}
```

---

## 10. Testing-Strategie

### 10.1 Unit Tests
```
â–¡ TtsService: speak, stop, language switching
â–¡ SttService: start/stop, permission handling
â–¡ CommandParser: Command matching, fuzzy matching
â–¡ AnnouncementBuilder: Template interpolation
â–¡ VoiceStrings: All languages, all templates
```

### 10.2 Integration Tests
```
â–¡ TTS â†’ Audio Output (mit Mock)
â–¡ STT â†’ Text Recognition (mit Mock)
â–¡ Full Flow: Button Press â†’ Recognition â†’ Action
```

### 10.3 Device Testing
```
â–¡ Android: Samsung, Pixel, Huawei (verschiedene TTS Engines)
â–¡ iOS: iPhone, iPad
â–¡ Verschiedene Sprachen pro Device
```

---

## 11. Rollout-Phasen

### Phase 1: MVP (2 Wochen)
```
â–¡ TTS Service mit flutter_tts
â–¡ Ticket-Status vorlesen (Patient App)
â–¡ Patienten-Aufruf TTS (Staff App)
â–¡ Sprachen: DE, EN
â–¡ Basic VoiceButton Widget
```

### Phase 2: STT Integration (2 Wochen)
```
â–¡ STT Service mit speech_to_text
â–¡ Sprachbefehle Patient App (Status, Wartezeit)
â–¡ Sprachen: DE, EN, TR, AR
â–¡ Command Parser
```

### Phase 3: Advanced Features (2 Wochen)
```
â–¡ Diktierfunktion Staff App
â–¡ Medizinisches Vokabular
â–¡ Cloud TTS Option (bessere QualitÃ¤t)
â–¡ Weitere Sprachen (Phase 2 Sprachen)
```

### Phase 4: Polish (1 Woche)
```
â–¡ Accessibility Audit
â–¡ Performance Optimierung
â–¡ Offline-Caching von Ansagen
â–¡ Dokumentation
```

---

## 12. Offene Fragen

| # | Frage | Entscheidung benÃ¶tigt von |
|---|-------|---------------------------|
| 1 | Cloud TTS Budget? (Google/Azure) | Product Owner |
| 2 | Wake Word gewÃ¼nscht? ("Hey Sanad") | Product Owner |
| 3 | Lautsprecher-Integration im Wartezimmer? | IT/Hardware |
| 4 | Dialekt-Support? (Schweizerdeutsch, Ã–sterreichisch) | Product Owner |
| 5 | HIPAA/DSGVO fÃ¼r Cloud STT? | Legal/Compliance |

---

## 13. AbhÃ¤ngigkeiten

```
BenÃ¶tigt vor Start:
  âœ… Core Package (Models)
  âœ… UI Package (Widgets)
  â³ Lokalisierung (i18n Setup)
  â³ Settings-Screen in allen Apps

Externe AbhÃ¤ngigkeiten:
  - flutter_tts Paket
  - speech_to_text Paket
  - (Optional) Cloud API Keys
```

---

## 14. GeschÃ¤tzte Story Points

| Feature | Story Points | PrioritÃ¤t |
|---------|-------------|-----------|
| TTS Service Setup | 3 | P0 |
| Ticket-Status TTS | 2 | P0 |
| Patienten-Aufruf TTS | 3 | P0 |
| VoiceButton Widget | 2 | P0 |
| SpeakButton Widget | 1 | P0 |
| STT Service Setup | 5 | P1 |
| Sprachbefehle Patient | 3 | P1 |
| Diktierfunktion Staff | 8 | P2 |
| Cloud TTS Integration | 5 | P2 |
| Medical Vocabulary | 5 | P2 |
| Weitere Sprachen (8) | 8 | P2 |
| **TOTAL** | **45 SP** | - |

---

**ğŸ“Œ REMINDER: Dies ist NUR ein Plan. Kein Code wurde geschrieben.**

**NÃ¤chster Schritt:** Dieser Plan wird von einem separaten Agent ausgefÃ¼hrt.
